Natural Language Processing, or NLP, is the sub-field of AI that is focused on enabling computers to understand and process human languages. 
NLP enables computers to understand natural language as humans do. Whether the language is spoken or written, natural language processing uses artificial intelligence to take real-world input, 
process it, and make sense of it in a way a computer can understand. Just as humans have different sensors -- such as ears to hear and eyes to see -- computers have programs to read and microphones to collect audio. 
And just as humans have a brain to process that input, computers have a program to process their respective inputs. 
At some point in processing, the input is converted to code that the computer can understand.

There are two main phases to natural language processing: data preprocessing and algorithm development.

Data preprocessing involves preparing and "cleaning" text data for machines to be able to analyze it. preprocessing puts data in workable form and highlights features in the text that an algorithm can work with. 
There are several ways this can be done, including: Tokenization, Stop word removal, stemming, lemmatization and part of speech tagging.

Once the data has been preprocessed, an algorithm is developed to process it. There are many different natural language processing algorithms, but two main types are commonly used:

Rules-based system. This system uses carefully designed linguistic rules. This approach was used early on in the development of natural language processing, and is still used.
Machine learning-based system. Machine learning algorithms use statistical methods. They learn to perform tasks based on training data they are fed, and adjust their methods as more data is processed. 
Using a combination of machine learning, deep learning and neural networks, 
natural language processing algorithms hone their own rules through repeated processing and learning.


